{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data Platform\n",
    "## Assignment 3: ServerLess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By:**  \n",
    "\n",
    "Oren Ben-Eliyahu 204079453 \n",
    "<br>Yuval Barkan, 205714447\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The goal of this assignment is to:**\n",
    "- Understand and practice the details of Serverless\n",
    "\n",
    "**Instructions:**\n",
    "- Students will form teams of two people each, and submit a single homework for each team.\n",
    "- The same score for the homework will be given to each member of your team.\n",
    "- Your solution is in the form of a Jupyter notebook file (with extension ipynb).\n",
    "- Images/Graphs/Tables should be submitted inside the notebook.\n",
    "- The notebook should be runnable and properly documented. \n",
    "- Please answer all the questions and include all your code.\n",
    "- You are expected to submit a clear and pythonic code.\n",
    "- You can change functions signatures/definitions.\n",
    "\n",
    "**Submission:**\n",
    "- Submission of the homework will be done via Moodle by uploading (not Zip):\n",
    "    - Jupyter Notebook\n",
    "    - 2 Log files\n",
    "    - Additional local scripts\n",
    "- The homework needs to be entirely in English.\n",
    "- The deadline for submission is on Moodle.\n",
    "- Late submission won't be allowed.\n",
    "\n",
    "  \n",
    "- In case of identical code submissions - both groups will get a Zero. \n",
    "- Some groups might be selected randomly to present their code.\n",
    "\n",
    "**Requirements:**  \n",
    "- Python 3.6 should be used.  \n",
    "- You should implement the algorithms by yourself using only basic Python libraries (such as numpy,pandas,etc.)\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grading:**\n",
    "- Q0 - 10 points - Setup\n",
    "- Q1 - 40 points - Serverless MapReduceEngine\n",
    "- Q2 - 20 points - MapReduce job to calculate inverted index\n",
    "- Q3 - 30 points - Shuffle\n",
    "\n",
    "`Total: 100`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 0\n",
    "## Setup\n",
    "\n",
    "1. Navigate to IBM Cloud and open a trial account. No need to provide a credit card\n",
    "2. Choose IBM Cloud Object Storage service from the catalog\n",
    "3. Create a new bucket in IBM Cloud Object Storage\n",
    "4. Create credentials for the bucket with HMAC (access key and secret key)\n",
    "5. Choose IBM Cloud Functions service from the catalog and create a service\n",
    "\n",
    "\n",
    "#### Lithops setup\n",
    "1. By using “git” tool, install master branch of the Lithops project from\n",
    "https://github.com/lithops-cloud/lithops\n",
    "2. Follow Lithops documentation and configure Lithops against IBM Cloud Functions and IBM Cloud Object Storage\n",
    "3. Configure Lithops log level to be in DEBUG mode\n",
    "4. Run Hello World example by using Futures API and verify all is working properly.\n",
    "\n",
    "\n",
    "#### IBM Cloud Object Storage setup\n",
    "1. Upload all the input CSV files that you used in homework 2 into the bucket you created in IBM Cloud Object Storage\n",
    "\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/lithops-cloud/lithops.git\n",
      "  Cloning https://github.com/lithops-cloud/lithops.git to /private/var/folders/lg/pbb4ypp52kx1shc2q76nnnlc0000gn/T/pip-req-build-hq6wsr1f\n",
      "Requirement already satisfied (use --upgrade to upgrade): lithops==2.5.9.dev0 from git+https://github.com/lithops-cloud/lithops.git in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages\n",
      "Requirement already satisfied: Click in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (7.1.2)\n",
      "Requirement already satisfied: pandas in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (1.1.3)\n",
      "Requirement already satisfied: PyYAML in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (5.3.1)\n",
      "Requirement already satisfied: python-dateutil in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (2.8.1)\n",
      "Requirement already satisfied: pika in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (4.50.2)\n",
      "Requirement already satisfied: lxml in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (4.6.1)\n",
      "Requirement already satisfied: tblib in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (1.7.0)\n",
      "Requirement already satisfied: docker in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (5.0.3)\n",
      "Requirement already satisfied: requests in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (2.24.0)\n",
      "Requirement already satisfied: seaborn in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (0.11.0)\n",
      "Requirement already satisfied: paramiko in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (2.9.1)\n",
      "Requirement already satisfied: matplotlib in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (3.3.2)\n",
      "Requirement already satisfied: kubernetes in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (21.7.0)\n",
      "Requirement already satisfied: ibm-cos-sdk in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (2.11.0)\n",
      "Requirement already satisfied: redis in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (4.1.0)\n",
      "Requirement already satisfied: ibm-vpc in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (1.6.0)\n",
      "Requirement already satisfied: ps-mem in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops==2.5.9.dev0) (3.12)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from pandas->lithops==2.5.9.dev0) (2020.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from pandas->lithops==2.5.9.dev0) (1.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from python-dateutil->lithops==2.5.9.dev0) (1.15.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from docker->lithops==2.5.9.dev0) (1.2.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests->lithops==2.5.9.dev0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests->lithops==2.5.9.dev0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests->lithops==2.5.9.dev0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests->lithops==2.5.9.dev0) (1.25.11)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from seaborn->lithops==2.5.9.dev0) (1.5.2)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from paramiko->lithops==2.5.9.dev0) (3.1.1)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from paramiko->lithops==2.5.9.dev0) (3.2.0)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from paramiko->lithops==2.5.9.dev0) (1.4.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from matplotlib->lithops==2.5.9.dev0) (8.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from matplotlib->lithops==2.5.9.dev0) (1.3.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from matplotlib->lithops==2.5.9.dev0) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from matplotlib->lithops==2.5.9.dev0) (0.10.0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from kubernetes->lithops==2.5.9.dev0) (50.3.1.post20201107)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from kubernetes->lithops==2.5.9.dev0) (2.3.3)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from kubernetes->lithops==2.5.9.dev0) (1.3.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-cos-sdk->lithops==2.5.9.dev0) (2.11.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-cos-sdk->lithops==2.5.9.dev0) (0.10.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-cos-sdk->lithops==2.5.9.dev0) (2.11.0)\n",
      "Requirement already satisfied: deprecated>=1.2.3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from redis->lithops==2.5.9.dev0) (1.2.13)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from redis->lithops==2.5.9.dev0) (21.3)\n",
      "Requirement already satisfied: ibm-cloud-sdk-core>=3.13.2 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-vpc->lithops==2.5.9.dev0) (3.13.2)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from cryptography>=2.5->paramiko->lithops==2.5.9.dev0) (1.14.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes->lithops==2.5.9.dev0) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes->lithops==2.5.9.dev0) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes->lithops==2.5.9.dev0) (4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests-oauthlib->kubernetes->lithops==2.5.9.dev0) (3.1.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from deprecated>=1.2.3->redis->lithops==2.5.9.dev0) (1.11.2)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-cloud-sdk-core>=3.13.2->ibm-vpc->lithops==2.5.9.dev0) (2.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycparser in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.5->paramiko->lithops==2.5.9.dev0) (2.20)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes->lithops==2.5.9.dev0) (0.4.8)\n",
      "Building wheels for collected packages: lithops\n",
      "  Building wheel for lithops (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lithops: filename=lithops-2.5.9.dev0-py3-none-any.whl size=313590 sha256=4b5718c6cb068658adf9d6b2667492e511987a5ed80b15a17f1daffba3219f7d\n",
      "  Stored in directory: /private/var/folders/lg/pbb4ypp52kx1shc2q76nnnlc0000gn/T/pip-ephem-wheel-cache-odav6kbn/wheels/f2/7a/47/12c1c1acee8bccb6b8e4b06ee26d13fe6f304831832bb2a33d\n",
      "Successfully built lithops\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/lithops-cloud/lithops.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-07 14:29:45,505 [INFO] lithops.config -- Lithops v2.5.9.dev0\n",
      "2022-01-07 14:29:45,509 [INFO] lithops.storage.backends.localhost.localhost -- Localhost storage client created\n",
      "2022-01-07 14:29:45,509 [INFO] lithops.localhost.localhost -- Localhost compute client created\n",
      "2022-01-07 14:29:45,509 [INFO] lithops.invokers -- ExecutorID be84c7-0 | JobID A000 - Selected Runtime: python \n",
      "2022-01-07 14:29:45,512 [INFO] lithops.invokers -- ExecutorID be84c7-0 | JobID A000 - Starting function invocation: hello() - Total: 1 activations\n",
      "2022-01-07 14:29:45,881 [INFO] lithops.invokers -- ExecutorID be84c7-0 | JobID A000 - View execution logs at /private/var/folders/lg/pbb4ypp52kx1shc2q76nnnlc0000gn/T/lithops/logs/be84c7-0-A000.log\n",
      "2022-01-07 14:29:45,881 [INFO] lithops.wait -- ExecutorID be84c7-0 - Getting results from functions\n",
      "\n",
      "  100%|██████████████████████████████████████████████████████████████████| 1/1  \n",
      "\n",
      "2022-01-07 14:29:47,930 [INFO] lithops.executors -- ExecutorID be84c7-0 - Cleaning temporary data\n",
      "\n",
      "Hello ah11500! Lithops is working as expected :)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!lithops test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lithops in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (2.5.9.dev0)\n",
      "Requirement already satisfied: aws in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (0.2.5)\n",
      "Requirement already satisfied: requests in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (2.24.0)\n",
      "Requirement already satisfied: kubernetes in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (21.7.0)\n",
      "Requirement already satisfied: cloudpickle in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (1.6.0)\n",
      "Requirement already satisfied: tqdm in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (4.50.2)\n",
      "Requirement already satisfied: seaborn in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (0.11.0)\n",
      "Requirement already satisfied: pika in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (1.2.0)\n",
      "Requirement already satisfied: ibm-vpc in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (0.9.0)\n",
      "Requirement already satisfied: tblib in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (1.7.0)\n",
      "Requirement already satisfied: redis in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (4.1.0)\n",
      "Requirement already satisfied: lxml in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (4.6.1)\n",
      "Requirement already satisfied: Click in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (7.1.2)\n",
      "Requirement already satisfied: paramiko in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (2.9.1)\n",
      "Requirement already satisfied: PyYAML in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (5.3.1)\n",
      "Requirement already satisfied: pandas in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (1.1.3)\n",
      "Requirement already satisfied: ps-mem in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (3.12)\n",
      "Requirement already satisfied: python-dateutil in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (2.8.1)\n",
      "Requirement already satisfied: ibm-cos-sdk in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (2.11.0)\n",
      "Requirement already satisfied: matplotlib in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (3.3.2)\n",
      "Requirement already satisfied: docker in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from lithops) (5.0.3)\n",
      "Requirement already satisfied: boto in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from aws) (2.49.0)\n",
      "Requirement already satisfied: fabric>=1.6 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from aws) (2.6.0)\n",
      "Requirement already satisfied: prettytable>=0.7 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from aws) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests->lithops) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests->lithops) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests->lithops) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests->lithops) (1.25.11)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from kubernetes->lithops) (2.3.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from kubernetes->lithops) (1.2.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from kubernetes->lithops) (1.15.0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from kubernetes->lithops) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from kubernetes->lithops) (1.3.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from seaborn->lithops) (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from seaborn->lithops) (1.19.2)\n",
      "Requirement already satisfied: ibm-cloud-sdk-core>=3.13.2 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-vpc->lithops) (3.13.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from redis->lithops) (21.3)\n",
      "Requirement already satisfied: deprecated>=1.2.3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from redis->lithops) (1.2.13)\n",
      "Requirement already satisfied: pynacl>=1.0.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from paramiko->lithops) (1.4.0)\n",
      "Requirement already satisfied: bcrypt>=3.1.3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from paramiko->lithops) (3.2.0)\n",
      "Requirement already satisfied: cryptography>=2.5 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from paramiko->lithops) (3.1.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from pandas->lithops) (2020.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-cos-sdk->lithops) (0.10.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.11.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-cos-sdk->lithops) (2.11.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-cos-sdk->lithops) (2.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from matplotlib->lithops) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from matplotlib->lithops) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from matplotlib->lithops) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from matplotlib->lithops) (8.0.1)\n",
      "Requirement already satisfied: invoke<2.0,>=1.3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from fabric>=1.6->aws) (1.6.0)\n",
      "Requirement already satisfied: pathlib2 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from fabric>=1.6->aws) (2.3.5)\n",
      "Requirement already satisfied: wcwidth in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from prettytable>=0.7->aws) (0.2.5)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes->lithops) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes->lithops) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from google-auth>=1.0.1->kubernetes->lithops) (4.2.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from requests-oauthlib->kubernetes->lithops) (3.1.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from ibm-cloud-sdk-core>=3.13.2->ibm-vpc->lithops) (2.3.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from deprecated>=1.2.3->redis->lithops) (1.11.2)\n",
      "Requirement already satisfied: cffi>=1.4.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from pynacl>=1.0.1->paramiko->lithops) (1.14.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes->lithops) (0.4.8)\n",
      "Requirement already satisfied: pycparser in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from cffi>=1.4.1->pynacl>=1.0.1->paramiko->lithops) (2.20)\n"
     ]
    }
   ],
   "source": [
    "!pip install lithops aws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (1.20.27)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from boto3) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.24.0,>=1.23.27 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from boto3) (1.23.27)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.27->boto3) (1.25.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from botocore<1.24.0,>=1.23.27->boto3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ah11500/opt/anaconda3/envs/yb1/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.27->boto3) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lithops\n",
    "import os\n",
    "import boto3\n",
    "from io import StringIO\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWSAccessKeyId = os.environ.get(\"AWSAccessKeyId\")\n",
    "AWSSecretKey = os.environ.get(\"AWSSecretKey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'lithops': {'backend': 'aws_lambda', 'storage': 'aws_s3', 'log_level':'DEBUG'},\n",
    "\n",
    "          'aws':  {'access_key_id': AWSAccessKeyId,\n",
    "                   'secret_access_key': AWSSecretKey},\n",
    "\n",
    "          'aws_s3': {'storage_bucket': 'idc-big-data',\n",
    "                     'region_name': 'eu-central-1'},\n",
    "          \n",
    "          'aws_lambda': {'execution_role': 'arn:aws:iam::981299761374:role/lithops-execution-role',\n",
    "                     'region_name': 'eu-central-1'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hello(name):\n",
    "#     return 'Hello {}!'.format(name)\n",
    "\n",
    "# with lithops.FunctionExecutor(config=config) as fexec:\n",
    "#     fut = fexec.call_async(hello, 'World')\n",
    "#     print(fut.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "## Serverless MapReduceEngine\n",
    "\n",
    "Modify MapReduceEngine from homework 2 into the MapReduceServerlessEngine where map and reduce tasks executed as a serverless actions, instead of local threads. In particular:\n",
    "1. Deploy all map tasks as a serverless actions by using Lithops against IBM Cloud Functions.\n",
    "2. Collect results from all map tasks and store them in the same SQLite as you used in MapReduceEngine and use the same code for the sort and shuffle phase.\n",
    "3. Deploy reduce tasks by using Lithops against IBM Cloud Functions. Instead of persisting results from reduce tasks, return results back to the MapReduceServerlessEngine and proceed with the same workflow as in MapReduceEngine\n",
    "4. Return results of reduce tasks to the user\n",
    "\n",
    "**Please attach:**  \n",
    "Text file with all log messages Lithops printed to console during the execution. Make\n",
    "sure log level is set to DEBUG mode.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\"oren\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_map_function(id, x):\n",
    "    print(\"I'm activation number {}\".format(id))\n",
    "    return x[1]['oren']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 14:52:30,647 [INFO] lithops.storage.backends.aws_s3.aws_s3 -- S3 client created - Region: eu-central-1\n"
     ]
    }
   ],
   "source": [
    "from lithops import Storage\n",
    "storage = Storage(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_of_values = ['csv_files/myCSV1.csv', {'column':2}]\n",
    "\n",
    "def my_map_function(list_of_values):\n",
    "    file = pd.read_csv(\"/Users/ah11500/Documents/GitHub/IDC/big_data/sec_ex/csv_files/myCSV1.csv\")\n",
    "    return file.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Steven', 'Dana', 'London'],\n",
       "       ['Marc', 'Michael', 'Haifa'],\n",
       "       ['Johanna', 'Marc', 'New York'],\n",
       "       ['Steven', 'Marc', 'Kiel'],\n",
       "       ['Michael', 'John', 'London'],\n",
       "       ['John', 'Albert', 'London'],\n",
       "       ['Michael', 'Marc', 'Kiel'],\n",
       "       ['Marc', 'Johanna', 'Palo Alto'],\n",
       "       ['John', 'Dana', 'London'],\n",
       "       ['Steven', 'Albert', 'New York']], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_map_function(['yuval','oren'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 14:58:38,792 [INFO] lithops.config -- Lithops v2.5.9.dev0\n",
      "2022-01-07 14:58:38,793 [INFO] lithops.storage.backends.localhost.localhost -- Localhost storage client created\n",
      "2022-01-07 14:58:38,794 [INFO] lithops.localhost.localhost -- Localhost compute client created\n",
      "2022-01-07 14:58:38,794 [INFO] lithops.invokers -- ExecutorID 835ef1-30 | JobID A000 - Selected Runtime: python \n",
      "2022-01-07 14:58:38,798 [INFO] lithops.invokers -- ExecutorID 835ef1-30 | JobID A000 - Starting function invocation: my_map_function() - Total: 1 activations\n",
      "2022-01-07 14:58:39,077 [INFO] lithops.invokers -- ExecutorID 835ef1-30 | JobID A000 - View execution logs at /private/var/folders/lg/pbb4ypp52kx1shc2q76nnnlc0000gn/T/lithops/logs/835ef1-30-A000.log\n",
      "2022-01-07 14:58:39,082 [INFO] lithops.wait -- ExecutorID 835ef1-30 - Getting results from functions\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f282ad7343f242bdb37325ce62926352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 14:58:41,120 [INFO] lithops.executors -- ExecutorID 835ef1-30 - Cleaning temporary data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[['Steven' 'Dana' 'London']\n",
      " ['Marc' 'Michael' 'Haifa']\n",
      " ['Johanna' 'Marc' 'New York']\n",
      " ['Steven' 'Marc' 'Kiel']\n",
      " ['Michael' 'John' 'London']\n",
      " ['John' 'Albert' 'London']\n",
      " ['Michael' 'Marc' 'Kiel']\n",
      " ['Marc' 'Johanna' 'Palo Alto']\n",
      " ['John' 'Dana' 'London']\n",
      " ['Steven' 'Albert' 'New York']]\n"
     ]
    }
   ],
   "source": [
    "fexec = lithops.FunctionExecutor()\n",
    "fexec.call_async(my_map_function, data=['csv_files/myCSV1.csv', {'column':2}])\n",
    "print(fexec.get_result())\n",
    "fexec.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_data):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_data)\n",
    "        print(\"Establish connection\")\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        return conn\n",
    "\n",
    "\n",
    "def create_table(conn, create_table_query):\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_query)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "        \n",
    "def query(conn, select_query):\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        select_all = select_query\n",
    "        rows = c.execute(select_all).fetchall()\n",
    "        # Output to the console screen\n",
    "        return rows\n",
    "    \n",
    "    except Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Establish connection\n"
     ]
    }
   ],
   "source": [
    "MYDATA_DB = 'temp_results.db'\n",
    "\n",
    "create_table_temp_results = '''CREATE TABLE IF NOT EXISTS temp_results(\n",
    "                                key TEXT,\n",
    "                                value TEXT)\n",
    "                            '''\n",
    "conn = create_connection(MYDATA_DB)\n",
    "create_table(conn,create_table_temp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as cf\n",
    "\n",
    "class MapReduceEngine():\n",
    "    \n",
    "    def execute(self, input_data, map_function, reduce_function, params):\n",
    "                        \n",
    "        # map function\n",
    "        s3_resource = boto3.resource('s3')\n",
    "        map_collector = []\n",
    "        for count, csv_file in enumerate(input_data):\n",
    "            map_result = fexec.call_async(map_function, csv_file, **params)\n",
    "            map_collector.append(map_result)\n",
    "\n",
    "        # Load contect of all CSV files into the temp_results table\n",
    "        for i in range(len(input_data)):\n",
    "            data = pd.read_csv(f'mapreducetemp/part-tmp-{i+1}.csv')\n",
    "            data.to_sql('temp_results',conn, if_exists='append',index=False)\n",
    "        \n",
    "        # SQL statements:\n",
    "        grouping_query = \"SELECT key, GROUP_CONCAT(value,',') FROM temp_results GROUP BY key\"\n",
    "        reduce_input_values = query(conn,grouping_query)\n",
    "        \n",
    "        unique_keys = \"SELECT  count(distinct key) FROM temp_results\"\n",
    "        reduce_threads = query(conn,unique_keys)[0][0]\n",
    "        \n",
    "        # reduce function\n",
    "        threads = []\n",
    "        \n",
    "        for i in range(reduce_threads):\n",
    "            with cf.ThreadPoolExecutor() as executor:\n",
    "                key = reduce_input_values[i][0]\n",
    "                values = reduce_input_values[i][1].split(',')\n",
    "                \n",
    "                t = executor.submit(reduce_function, key, values)             \n",
    "                df = t.result()\n",
    "                df.to_csv(f'mapreducefinal/part-{i+1}-final.csv', index=False)\n",
    "                threads.append(t)\n",
    "        \n",
    "        # Check if all threads are completed:   \n",
    "        if len(threads) != reduce_threads:\n",
    "            print(\"MapReduce Failed\")\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            print(\"MapReduce Completed\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lithops import Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 13:18:42,087 [DEBUG] lithops.config -- Loading Storage backend module: aws_s3\n",
      "2022-01-07 13:18:42,088 [DEBUG] lithops.storage.backends.aws_s3.aws_s3 -- Creating S3 client\n",
      "2022-01-07 13:18:42,094 [INFO] lithops.storage.backends.aws_s3.aws_s3 -- S3 client created - Region: eu-central-1\n"
     ]
    }
   ],
   "source": [
    "storage = Storage(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_list = storage.list_objects('idc-big-data', prefix='csv_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csv_files/myCSV1.csv',\n",
       " 'csv_files/myCSV10.csv',\n",
       " 'csv_files/myCSV11.csv',\n",
       " 'csv_files/myCSV12.csv',\n",
       " 'csv_files/myCSV13.csv',\n",
       " 'csv_files/myCSV14.csv',\n",
       " 'csv_files/myCSV15.csv',\n",
       " 'csv_files/myCSV16.csv',\n",
       " 'csv_files/myCSV17.csv',\n",
       " 'csv_files/myCSV18.csv',\n",
       " 'csv_files/myCSV19.csv',\n",
       " 'csv_files/myCSV2.csv',\n",
       " 'csv_files/myCSV20.csv',\n",
       " 'csv_files/myCSV3.csv',\n",
       " 'csv_files/myCSV4.csv',\n",
       " 'csv_files/myCSV5.csv',\n",
       " 'csv_files/myCSV6.csv',\n",
       " 'csv_files/myCSV7.csv',\n",
       " 'csv_files/myCSV8.csv',\n",
       " 'csv_files/myCSV9.csv']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data =[]\n",
    "for file in files_list:\n",
    "    input_data.append(file['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "params = {'column':2}\n",
    "list_mycsv = []\n",
    "def inverted_map(input_data, column_index=0):\n",
    "    s=str(storage.get_object('idc-big-data',document_name),'utf-8')\n",
    "    data_1 = StringIO(s)\n",
    "    file=pd.read_csv(data_1)\n",
    "    for value in file.iloc[:,column_index['column']].values:\n",
    "        list_mycsv.append((value,document_name))\n",
    "    return list_mycsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverted_map('csv_files/myCSV1.csv',params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 14:28:56,141 [INFO] lithops.config -- Lithops v2.5.9.dev0\n",
      "2022-01-07 14:28:56,142 [DEBUG] lithops.config -- Loading Serverless backend module: aws_lambda\n",
      "2022-01-07 14:28:56,142 [DEBUG] lithops.config -- Loading Storage backend module: aws_s3\n",
      "2022-01-07 14:28:56,143 [DEBUG] lithops.storage.backends.aws_s3.aws_s3 -- Creating S3 client\n",
      "2022-01-07 14:28:56,148 [INFO] lithops.storage.backends.aws_s3.aws_s3 -- S3 client created - Region: eu-central-1\n",
      "2022-01-07 14:28:56,149 [DEBUG] lithops.serverless.backends.aws_lambda.aws_lambda -- Creating AWS Lambda client\n",
      "2022-01-07 14:28:56,149 [DEBUG] lithops.serverless.backends.aws_lambda.aws_lambda -- Creating Boto3 AWS Session and Lambda Client\n",
      "2022-01-07 14:28:57,129 [INFO] lithops.serverless.backends.aws_lambda.aws_lambda -- AWS Lambda client created - Region: eu-central-1\n",
      "2022-01-07 14:28:57,131 [DEBUG] lithops.invokers -- ExecutorID 1f1011-26 - Invoker initialized. Max workers: 1000\n",
      "2022-01-07 14:28:57,131 [DEBUG] lithops.invokers -- ExecutorID 1f1011-26 - Serverless invoker created\n",
      "2022-01-07 14:28:57,132 [DEBUG] lithops.executors -- Function executor for aws_lambda created with ID: 1f1011-26\n",
      "2022-01-07 14:28:57,132 [INFO] lithops.invokers -- ExecutorID 1f1011-26 | JobID M000 - Selected Runtime: python38 - 256MB\n",
      "2022-01-07 14:28:57,133 [DEBUG] lithops.storage.storage -- Runtime metadata found in local memory cache\n",
      "2022-01-07 14:28:57,134 [DEBUG] lithops.job.job -- ExecutorID 1f1011-26 | JobID M000 - Serializing function and data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_hashlib.HASH' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-84c70f53d11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmap_collector\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfexec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlithops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfexec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverted_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csv_files/myCSV9.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfexec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/executors.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_function, map_iterdata, chunksize, extra_args, extra_env, runtime_memory, obj_chunk_size, obj_chunk_number, timeout, include_modules, exclude_modules)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mruntime_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         job = create_map_job(config=self.config,\n\u001b[0m\u001b[1;32m    261\u001b[0m                              \u001b[0minternal_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                              \u001b[0mexecutor_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/job/job.py\u001b[0m in \u001b[0;36mcreate_map_job\u001b[0;34m(config, internal_storage, executor_id, job_id, map_function, iterdata, runtime_meta, runtime_memory, extra_env, include_modules, exclude_modules, execution_timeout, chunksize, extra_args, obj_chunk_size, obj_chunk_number)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     job = _create_job(config=config,\n\u001b[0m\u001b[1;32m     67\u001b[0m                       \u001b[0minternal_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternal_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                       \u001b[0mexecutor_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/job/job.py\u001b[0m in \u001b[0;36m_create_job\u001b[0;34m(config, internal_storage, executor_id, job_id, func, iterdata, runtime_meta, runtime_memory, extra_env, include_modules, exclude_modules, execution_timeout, host_job_meta, chunksize)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mjob_serialize_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializeIndependent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preinstalls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mfunc_and_data_ser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0miterdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_modules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_modules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mdata_strs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_data_ser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdata_size_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_strs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/job/serialize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, list_of_objs, include_modules, exclude_modules)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_objs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mmods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_inspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mstrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Add modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"recursion\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_hashlib.HASH' object"
     ]
    }
   ],
   "source": [
    "map_collector=[]\n",
    "fexec = lithops.FunctionExecutor(config=config)\n",
    "fexec.map(inverted_map, 'csv_files/myCSV9.csv')\n",
    "print(fut.get_result())\n",
    "fexec.clean()\n",
    "#map_collector.append(map_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-07 14:24:21,663 [INFO] lithops.config -- Lithops v2.5.9.dev0\n",
      "2022-01-07 14:24:21,664 [DEBUG] lithops.config -- Loading Serverless backend module: aws_lambda\n",
      "2022-01-07 14:24:21,664 [DEBUG] lithops.config -- Loading Storage backend module: aws_s3\n",
      "2022-01-07 14:24:21,665 [DEBUG] lithops.storage.backends.aws_s3.aws_s3 -- Creating S3 client\n",
      "2022-01-07 14:24:21,669 [INFO] lithops.storage.backends.aws_s3.aws_s3 -- S3 client created - Region: eu-central-1\n",
      "2022-01-07 14:24:21,669 [DEBUG] lithops.serverless.backends.aws_lambda.aws_lambda -- Creating AWS Lambda client\n",
      "2022-01-07 14:24:21,670 [DEBUG] lithops.serverless.backends.aws_lambda.aws_lambda -- Creating Boto3 AWS Session and Lambda Client\n",
      "2022-01-07 14:24:22,401 [INFO] lithops.serverless.backends.aws_lambda.aws_lambda -- AWS Lambda client created - Region: eu-central-1\n",
      "2022-01-07 14:24:22,403 [DEBUG] lithops.invokers -- ExecutorID 1f1011-23 - Invoker initialized. Max workers: 1000\n",
      "2022-01-07 14:24:22,404 [DEBUG] lithops.invokers -- ExecutorID 1f1011-23 - Serverless invoker created\n",
      "2022-01-07 14:24:22,404 [DEBUG] lithops.executors -- Function executor for aws_lambda created with ID: 1f1011-23\n",
      "2022-01-07 14:24:22,405 [INFO] lithops.invokers -- ExecutorID 1f1011-23 | JobID M000 - Selected Runtime: python38 - 256MB\n",
      "2022-01-07 14:24:22,405 [DEBUG] lithops.storage.storage -- Runtime metadata found in local memory cache\n",
      "2022-01-07 14:24:22,406 [DEBUG] lithops.job.job -- ExecutorID 1f1011-23 | JobID M000 - Serializing function and data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_hashlib.HASH' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-211-e41b12bbb750>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mlithops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfexec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mfut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfexec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverted_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mmap_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mmap_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/executors.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_function, map_iterdata, chunksize, extra_args, extra_env, runtime_memory, obj_chunk_size, obj_chunk_number, timeout, include_modules, exclude_modules)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mruntime_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         job = create_map_job(config=self.config,\n\u001b[0m\u001b[1;32m    261\u001b[0m                              \u001b[0minternal_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                              \u001b[0mexecutor_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/job/job.py\u001b[0m in \u001b[0;36mcreate_map_job\u001b[0;34m(config, internal_storage, executor_id, job_id, map_function, iterdata, runtime_meta, runtime_memory, extra_env, include_modules, exclude_modules, execution_timeout, chunksize, extra_args, obj_chunk_size, obj_chunk_number)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     job = _create_job(config=config,\n\u001b[0m\u001b[1;32m     67\u001b[0m                       \u001b[0minternal_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternal_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                       \u001b[0mexecutor_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/job/job.py\u001b[0m in \u001b[0;36m_create_job\u001b[0;34m(config, internal_storage, executor_id, job_id, func, iterdata, runtime_meta, runtime_memory, extra_env, include_modules, exclude_modules, execution_timeout, host_job_meta, chunksize)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mjob_serialize_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializeIndependent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preinstalls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mfunc_and_data_ser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0miterdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_modules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_modules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mdata_strs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_data_ser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdata_size_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_strs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/job/serialize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, list_of_objs, include_modules, exclude_modules)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_objs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mmods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_inspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mstrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Add modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"recursion\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_hashlib.HASH' object"
     ]
    }
   ],
   "source": [
    "map_collector=[]\n",
    "with lithops.FunctionExecutor(config=config) as fexec:\n",
    "    for count, csv_file in enumerate(input_data):\n",
    "        fut = fexec.map(inverted_map, [csv_file])\n",
    "        map_result = fut.get_result()\n",
    "        map_collector.append(map_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'column': 2}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(aws_access_key_id = os.environ.get(\"AWSAccessKeyId\"),\n",
    "                    aws_secret_access_key = os.environ.get(\"AWSSecretKey\"))\n",
    "\n",
    "s3 = session.resource('s3')\n",
    "\n",
    "my_bucket = s3.Bucket('idc-big-data')\n",
    "input_data = []\n",
    "\n",
    "for file in my_bucket.objects.filter(Prefix = 'csv_files/'):\n",
    "    input_data.append(file.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'idc-big-data'\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of map function is to create csv files. \n",
    "# Therfore we chose to optimize the process and not create unnecessary variables (such as list) and return a data frame. \n",
    "\n",
    "def inverted_map(document_name:str, column_index:dict):\n",
    "    obj = s3.get_object(Bucket= bucket, Key= document_name)\n",
    "    file = pd.read_csv(obj['Body'])\n",
    "    print(type(file))\n",
    "    df = pd.DataFrame({'key':file.iloc[:,column_index['column']],'value':csv_dir})\n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'column':2}\n",
    "# s3_resource = boto3.resource('s3')\n",
    "# for count, csv_file in enumerate(input_data):\n",
    "#     fexec = lithops.FunctionExecutor(config=config)\n",
    "#     fexec.map(inverted_map, csv_file, extra_args=params)\n",
    "#     df = fexec.get_result()\n",
    "#     csv_buffer = StringIO()\n",
    "#     df.to_csv(csv_buffer)\n",
    "#     s3_resource.Object('idc-big-data', f'mapreducetemp/part-tmp-{count+1}.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-05 21:19:59,449 [INFO] lithops.config -- Lithops v2.5.9.dev0\n",
      "2022-01-05 21:19:59,450 [DEBUG] lithops.config -- Loading Serverless backend module: aws_lambda\n",
      "2022-01-05 21:19:59,451 [DEBUG] lithops.config -- Loading Storage backend module: aws_s3\n",
      "2022-01-05 21:19:59,452 [DEBUG] lithops.storage.backends.aws_s3.aws_s3 -- Creating S3 client\n",
      "2022-01-05 21:19:59,456 [INFO] lithops.storage.backends.aws_s3.aws_s3 -- S3 client created - Region: eu-central-1\n",
      "2022-01-05 21:19:59,457 [DEBUG] lithops.serverless.backends.aws_lambda.aws_lambda -- Creating AWS Lambda client\n",
      "2022-01-05 21:19:59,457 [DEBUG] lithops.serverless.backends.aws_lambda.aws_lambda -- Creating Boto3 AWS Session and Lambda Client\n",
      "2022-01-05 21:20:00,268 [INFO] lithops.serverless.backends.aws_lambda.aws_lambda -- AWS Lambda client created - Region: eu-central-1\n",
      "2022-01-05 21:20:00,270 [DEBUG] lithops.invokers -- ExecutorID 1f1011-10 - Invoker initialized. Max workers: 1000\n",
      "2022-01-05 21:20:00,271 [DEBUG] lithops.invokers -- ExecutorID 1f1011-10 - Serverless invoker created\n",
      "2022-01-05 21:20:00,271 [DEBUG] lithops.executors -- Function executor for aws_lambda created with ID: 1f1011-10\n",
      "2022-01-05 21:20:00,272 [INFO] lithops.invokers -- ExecutorID 1f1011-10 | JobID M000 - Selected Runtime: python38 - 256MB\n",
      "2022-01-05 21:20:00,272 [DEBUG] lithops.storage.storage -- Runtime metadata found in local memory cache\n",
      "2022-01-05 21:20:00,273 [DEBUG] lithops.job.job -- ExecutorID 1f1011-10 | JobID M000 - Serializing function and data\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_hashlib.HASH' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-3c6564b833b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfexec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlithops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFunctionExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfexec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverted_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'myCSV1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfexec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcsv_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/executors.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_function, map_iterdata, chunksize, extra_args, extra_env, runtime_memory, obj_chunk_size, obj_chunk_number, timeout, include_modules, exclude_modules)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mruntime_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_runtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         job = create_map_job(config=self.config,\n\u001b[0m\u001b[1;32m    261\u001b[0m                              \u001b[0minternal_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                              \u001b[0mexecutor_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/job/job.py\u001b[0m in \u001b[0;36mcreate_map_job\u001b[0;34m(config, internal_storage, executor_id, job_id, map_function, iterdata, runtime_meta, runtime_memory, extra_env, include_modules, exclude_modules, execution_timeout, chunksize, extra_args, obj_chunk_size, obj_chunk_number)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# ########\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     job = _create_job(config=config,\n\u001b[0m\u001b[1;32m     67\u001b[0m                       \u001b[0minternal_storage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternal_storage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                       \u001b[0mexecutor_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/job/job.py\u001b[0m in \u001b[0;36m_create_job\u001b[0;34m(config, internal_storage, executor_id, job_id, func, iterdata, runtime_meta, runtime_memory, extra_env, include_modules, exclude_modules, execution_timeout, host_job_meta, chunksize)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mjob_serialize_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mserializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSerializeIndependent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruntime_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'preinstalls'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mfunc_and_data_ser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0miterdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_modules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_modules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0mdata_strs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_data_ser\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mdata_size_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_strs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/lithops/job/serialize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, list_of_objs, include_modules, exclude_modules)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_objs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mmods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_module_inspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mstrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Add modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, protocol, buffer_callback)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffer_callback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             )\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/yb1/lib/python3.8/site-packages/cloudpickle/cloudpickle_fast.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"recursion\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle '_hashlib.HASH' object"
     ]
    }
   ],
   "source": [
    "fexec = lithops.FunctionExecutor(config=config)\n",
    "fexec.map(inverted_map, 'myCSV1.csv', extra_args=params)\n",
    "df = fexec.get_result()\n",
    "csv_buffer = StringIO()\n",
    "df.to_csv(csv_buffer)\n",
    "s3_resource.Object('idc-big-data', 'mapreducetemp/part-tmp-1.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The goal of reduce function is to create csv files. \n",
    "# Therfore we chose to optimize the process and not create unnecessary variables (such as list) and return a data frame. \n",
    "\n",
    "def inverted_reduce(key,documents):\n",
    "    df = pd.DataFrame({'key':key,'value':list(set(documents))})\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "s3_client = boto3.client('s3', region_name='eu-central-1', \n",
    "                         aws_access_key_id = os.environ.get(\"AWSAccessKeyId\"),\n",
    "                         aws_secret_access_key = os.environ.get(\"AWSSecretKey\"))\n",
    "\n",
    "def upload_my_file(bucket, folder, file_to_upload, file_name):\n",
    "\n",
    "    key = folder+\"/\"+file_name\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_to_upload, bucket, key)\n",
    "    except ClientError as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapreduce = MapReduceEngine()\n",
    "params = {'column':2}\n",
    "status = mapreduce.execute(input_data, inverted_map, inverted_reduce, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "## Submit MapReduce job to calculate inverted index\n",
    "1. Use input_data: `cos://bucket/<path to CSV data>`\n",
    "2. Submit MapReduce job with reduce and map functions as you used in homework 2, as follows\n",
    "\n",
    "    `mapreduce = MapReduceServerlessEngine()`  \n",
    "    `results = mapreduce.execute(input_data, inverted_map, inverted_index)`   \n",
    "    `print(results)`\n",
    "\n",
    "**Please attach:**  \n",
    "Text file with all log messages Lithops printed to console during the execution. Make\n",
    "sure log level is set to DEBUG mode.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "## Shuffle\n",
    "\n",
    "MapReduceServerlessEngine deploys both map and reduce tasks as serverless invocations.   \n",
    "However, once map stage completed, the result are transferred from the map tasks to the SQLite database located on the client machine (laptop in your case), then performed local shuffle and then invoked reduce tasks passing them relevant parameters.\n",
    "\n",
    "(To support your answers, feel free to use examples, Images, etc.)\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Explain why this approach is not efficient and what are cons and pros of such architecture in general. In broader scope you may assume that MapReduceServerlessEngine executed in some powerful machine and not just laptop.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<your answer here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**2. Suggest how can you improve shuffle so intermediate data will not be downloaded to the client at all and shuffle performed in the cloud as well. Explain pros and cons of the approaches you suggest.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<your answer here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "**3. Can you make serverless shuffle?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\<your answer here>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "Good Luck :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
